# Pythonプロジェクト仕様書

## 目次
1. [はじめに](#1-はじめに)
2. [ファイル構成](#2-ファイル構成)
3. [技術スタック](#3-技術スタック)
4. [コードの機能概要](#4-コードの機能概要)
5. [実行方法](#5-実行方法)
6. [エラーハンドリングとログ記録](#6-エラーハンドリングとログ記録)
7. [テスト計画](#7-テスト計画)
8. [将来的な拡張](#8-将来的な拡張)
9. [まとめ](#9-まとめ)

---

## 1. はじめに


本プロジェクトは、画像ファイルから特定の情報を抽出し、その結果をエクセルファイルとして出力することを目的としています。特に、Microsoft AzureのDocument Intelligence機能を利用し、OCR（光学文字認識）を通じて、画像内のテキストデータを効果的に扱うことに焦点を当てています。

### プロジェクトの背景

デジタルデータの利活用が進む現代において、企業や個人はますます多くの情報を効率的に管理する必要があります。特に、大量の紙資料や画像データが存在する場合、それらから必要な情報を快速かつ正確に抽出し、分析可能な形式に変換することは重要です。本プロジェクトでは、これを実現するために、Azure Document Intelligenceを利用することで、効率的かつ高精度なデータ抽出を目指します。

### プロジェクトの目的

本プロジェクトの具体的な目的は以下の通りです。

1. 画像ファイル（特にPNG形式）の解析を行い、テキストデータを抽出すること。
2. 複数のソース（OCR結果や他のデータ）から得た情報を統合し、ひとつのエクセルファイルに整理すること。
3. ユーザーが簡単にデータを参照、管理できるようにすること。

### 本仕様書の目的

本仕様書は、プロジェクトの全体像を把握するために必要な情報を提供します。具体的には、以下の内容を含みます。

- プログラムの概要と構成要素
- ソースコードの詳細な説明
- モジュールの利用方法や機能
- 処理の流れや注意点

### 開発チーム及び関係者の紹介

本プロジェクトには、多様なスキルを持つ開発チームが参加しています。チームには、データサイエンティスト、ソフトウェアエンジニア、UI/UXデザイナー、プロジェクトマネージャーなどが含まれており、それぞれが専門技術を駆使し、プロジェクトの成功に貢献しています。

プロジェクトに関与する主要な関係者は以下の通りです。

- プロジェクトリーダー: プロジェクト全体の進行と監督を担当
- データサイエンティスト: データ分析およびモデルの選定を担当
- エンジニア: スクリプト作成やシステムの実装を担当
- テスター: 結果が期待通りになるよう、システムの検証を担当

このプロジェクトを通じて、関係者は最新の技術を学び、実際のデータ処理に応用する機会を得ることが期待されています。プロジェクトの成功に向けて、チーム全体が協力し合い、相互にサポートしていく方針です。

## 2. ファイル構成


本セクションでは、プロジェクトに含まれる各ファイルの構成とそれぞれの役割を詳細に説明します。また、センシティブなファイルについての概要、用途、保護された情報の管理方法についても触れます。

### センシティブなファイル: sample.pfx

- **ファイル目的**: 本ファイルは、セキュアなデータ管理および暗号化に関連する用途で利用されると思われます。
- **用途**: 特定の通信やデータストレージにおいて、暗号化装置や署名認証を行うために使用されます。
- **情報管理方法**: このファイルは、アクセスや使用を制限することで保護が図られているため、開示できる情報はありません。

### LargeFile.py の詳細構成

本プロジェクトにおける `LargeFile.py` スクリプトは、主に画像ファイルを処理し、その結果をExcelファイルとして出力するために設計されています。以下に、このスクリプトの構成要素を明確に区分して説明します。

#### 1. モジュールのインポート
- `import os`:
  - ファイルやディレクトリの操作を行うために使用されています。
  
- `import function_fin`:
  - ファイル出力や最終処理に関する機能が含まれるカスタムモジュールとして利用されます。

- `import function_7_document_intelligence`:
  - Document Intelligenceに特有の機能を含むカスタムモジュールであり、画像から情報を抽出する際に重要な役割を果たします。

#### 2. ベースフォルダのパス設定
- `base_folder`:
  - プログラムがデータを読み込むための基本フォルダのパスを設定しており、解析する画像ファイルや出力するエクセルファイルの基準点となります。

#### 3. 処理の流れ
- スクリプト内のコメントには、エラー処理の方法や使用するフォルダ名についてのガイドラインが示されており、エラー発生時には、別のフォルダでスクリプトを実行することが提案されています。
- 読み取る基本情報（小計、合計、総税額、取得日、取得時間）についても説明があり、どのように利用されるかの方向性が示されています。

#### 4. 画像処理のための関数
- **自然順序のソート関数 (`natural_sort_key`)**:
  - 自然順序でソートするためのキーを生成します。整形した文字列から数値を適切に処理することでソートの精度を高めています。

- **PNGフォルダ処理関数 (`process_png_folder`)**:
  - 指定されたフォルダ内のPNG画像ファイルを処理するメイン機能を持ちます。各サブフォルダに対してさらに探索を行い、条件を満たす場合にOCR処理を行う他の関数を呼び出します。

#### 5. 請求書データ処理
- **end_row, end_col**:
  - データフレームの行数と列数を参照し、テーブルの終了位置の管理を行います。

- **apply_borders**:
  - 処理結果のエクセルファイルにテーブルのボーダーを適用します。

- **adjust_column_widths**:
  - 列の幅を適切に調整して出力されたExcelシートの視覚的な整えに寄与します。

#### 6. プログラムの全体の流れ
このスクリプトは、ベースフォルダ内のサブフォルダを探索し、条件に一致するサブフォルダ内のPNGファイルに対して処理を行い、結果を指定された出力フォルダに保存します。すべての処理は関数に整理されており、高い可読性を持った構造になっています。

## 3. 技術スタック


本プロジェクトでは、主に以下の技術やライブラリを使用しています。各技術がプロジェクトの目的にどのように貢献しているかについても説明します。

### Python

Pythonは本プロジェクトの主要なプログラミング言語として使用されており、以下の点においてプロジェクトの成功に寄与しています。

- **高い可読性とシンプルさ**: Pythonは文法がシンプルであるため、開発者が容易にコードを理解しやすく、メンテナンスが容易です。これにより、複雑な処理を構築する際にも高い生産性を維持できます。
- **豊富なライブラリ**: Pythonには様々な機能を提供するライブラリが豊富に存在します。これにより、OCRやデータ処理の機能を迅速に実装できます。

### YAML

YAMLはプロジェクトの設定ファイルフォーマットとして使用されます。その利点は以下の通りです。

- **人間可読性**: YAMLは構造が分かりやすく、設定内容を直感的に理解できるため、設定や構成の変更が容易です。このことは、プロジェクトの構成を迅速に見直すことができるため、メンテナンス作業の効率化に寄与します。
- **ネスト構造の表現**: YAMLは階層的なデータ構造を簡潔に記述できるため、複雑な設定を持つシステムでも見通しが良い形で定義できます。

### OCR関連技術

プロジェクトでは、光学文字認識（OCR）に関する技術が重要な役割を果たしています。以下に、その利点を示します。

#### Aspose.OCR

- **性能**: `aspose.ocr`ライブラリを利用することで、高精度な文字認識を実現しています。OCRの精度が高まることで、データの取得や分析が正確になります。
- **効率的な画像処理**: このライブラリは大量の画像データに対しても効率的に処理を行うことが可能であり、高スループットが要求されるビジネスニーズに応えます。

#### Azure Document Intelligence

- **データ抽出の自動化**: Azure Document Intelligenceを使用することで、膨大な画像データから必要な情報を自動的に抽出できます。手動によるデータ処理を減少させ、ビジネスの効率を大幅に向上させます。
- **多様なデータ形式のサポート**: 画像だけでなく、異なる形式のドキュメントからも情報を抽出できるため、柔軟性と適応性が向上し、多様なビジネス要求に対応できます。

#### Python Imaging Library (PIL)

- **画像処理機能**: PILは画像を読み込み、変換、保存するといった処理を容易に行うためのライブラリです。これにより、画像データに対する前処理を簡単に実施でき、OCR処理の準備段階としての重要な役割を担います。

### 結論

本プロジェクトは、Pythonを基盤とし、YAMLによる設定管理や、OCR関連技術によって情報抽出を実現しています。これにより、業務の効率化やデータ分析力の向上が実現されており、最終的にはビジネス上の利益に繋がることが期待されます。各技術が相互に作用し、プロジェクト全体の目的を効果的に達成するための重要な要素となっています。

## 4. コードの機能概要


このセクションでは、指定されたソースコードファイルにおける各機能の詳細を説明し、全般的な処理フローを解説いたします。特にOCRや画像処理に関連する機能については、用語を統一し、一貫した表現で理解しやすくまとめます。

### 全体の目的
このソースコードは、指定されたフォルダ内のPNG画像を処理し、OCR（Optical Character Recognition）技術を用いて画像を解析・整形するためのものであり、特にディレクトリ内の特定のフォルダ構造に従って動作します。

### 主な構成要素

#### 1. ライブラリのインポート
コードでは以下のライブラリがインポートされ、各機能に利用されています：
- **os**: ファイルやディレクトリの操作を行うための標準ライブラリ。
- **re**: 正規表現を使用した文字列操作に利用。
- **aspose.ocr**: OCR処理を行うためのAsposeライブラリ。
- **PIL**: 画像処理を行うために利用するPython Imaging Library。

#### 2. OCR APIの初期化とフォルダパス設定
- `api`: OCR画像処理用のインスタンスを生成し、OCR処理に必要となる設定を行います。
- `base_folder`: これはOCR処理対象の画像が格納されているフォルダのパスで、ユーザーの環境によって異なるため、各環境に応じた設定が必要です。

#### 3. 自然順序のソート関数 (`natural_sort_key`)
- 入力された文字列を自然順序でソートするためのキーを返す関数です。この関数は、数値を含んだ文字列に対して適切な順序でのソートを行うためのロジックを実装しています。
- `re.split(r"(\\d+)", s)`を使用して文字列を数値部分で分割し、それぞれの部分を整数または小文字に変換してリストとして返します。

#### 4. PNGフォルダ処理関数 (`process_png_folder`)
- 指定されたフォルダ内のすべてのPNG画像ファイルを処理するための関数です。この関数では、以下の処理フローが実行されると思われます（具体的なアルゴリズムやロジックは非表示のため、詳細は不明）。
  - フォルダ内の画像ファイルを探索し、適切な処理を指定します。
  - 結果の保存先なども考慮され、OCR処理が行われると予測されます。

#### 5. フォルダ及びファイル処理フロー
- `os.walk(base_folder)`: 指定されたベースフォルダ及びそのサブフォルダ内の全てのディレクトリとファイルを再帰的に取得します。  
  - 各サブディレクトリが条件に合致する場合（例：名前が"ocr_only"で終わる）、処理が実施されます。
  
- **フォルダ名の条件確認**: フォルダ名により処理対象が制御され、例えば、特定の文字列("UVDoc")を含まない場合にのみ処理が行われます。

- **出力フォルダの作成**: 出力フォルダは、新しいサブフォルダとして作成されるか、既存の場合はスキップされます。
- **ファイル処理とOCRの実行**: 指定されたディレクトリ内のファイルを走査し、特定の拡張子（例: `.json`）のファイルが見つかると、それに基づいた処理（例: OCR処理）が行われます。

#### 6. 重要な処理の流れ
- **画像の読み込み**: 画像ファイルを開き、OCR処理を通じてテキストデータの抽出を実施します。
- **データ処理による座標の取得**: 処理したデータからキーワードの座標を取得し、画像の方向性を判断します。

### 結論
このソースコードは、指定されたディレクトリ内の画像ファイルに対してOCR処理を行うための一連の機能を包括的に提供しています。自然順序のソートやファイルの走査を通じて、必要な画像を効率よく処理する仕組みを有しており、各種メソッドが整理されているため、実装の理解が深まります。重要な部分でセンシティブな情報については、一般的な取り扱いについてのみ触れましたが、その内容はソースコードに依存するため、具体的な実装の詳細は非表示になっています。

## 5. 実行方法


本セクションでは、プロジェクトのコードを実行するための詳細な手順を説明します。以下に示す手順は、ユーザーが必要とするすべてのセットアップ、依存関係のインストール、実行方法を含んでいます。

### 必要条件

- Python 3.x がインストールされていることを確認してください。次のコマンドで確認できます：

  ```bash
  python --version
  ```

- 必要なライブラリがインストールされていることを確認します。次の依存関係を使用します：

  - `aspose.ocr`
  - `Pillow`
  - `pyyaml`

これらは `pip` を使ってインストールできます。以下はインストールコマンドの例です：

```bash
pip install aspose.ocr Pillow pyyaml
```

### セットアップ手順

1. **プロジェクトのクローンまたはダウンロード**

   プロジェクトリポジトリをクローンまたはZIP形式でダウンロードします。クローンするには以下のコマンドを使用します：

   ```bash
   git clone <リポジトリのURL>
   cd <ダウンロードしたフォルダ>
   ```

2. **YAML設定ファイルの設定**

   `config.yml`ファイルを適切な内容に設定します。このファイルはアプリケーションの設定内容を格納しています。詳細な内容は非表示のため、具体的な設定はユーザー自身で確認してください。このファイルには以下のような項目が含まれることが一般的です：

   - サービス設定
   - データベース接続情報
   - API キーなど

3. **画像ファイルの準備**

   `base_folder`変数で指定されるフォルダ内に、OCR処理を行いたいPNG画像ファイルを配置します。このフォルダのパスは、ユーザーの環境に合わせて適切に設定する必要があります。

   ```python
   base_folder = "path/to/your/images"
   ```

   画像ファイルの拡張子はPNGでなければならないことを確認してください。

### コードの実行

以下のコマンドを使用して、Pythonスクリプトを実行します：

```bash
python code/code_sample_python/LargeFile.py
```

スクリプト実行中に発生する可能性のあるエラーや例外の処理に関しては、コード内のコメントやドキュメントに従って対応してください。

### センシティブデータへのアクセス

アプリケーション動作に必要なセンシティブなデータへのアクセスは、`config.yml`ファイルで設定します。このファイルに含まれる情報はアプリケーションの動作に重要なので、別途安全に管理してください。特にAPIキーやパスワードなどの機密情報は、外部に漏洩しないよう注意が必要です。

### 注意事項

- 実行環境によっては、ファイアウォールやセキュリティポリシーが影響する場合があります。必要に応じて、設定を見直してください。
- スクリプトのテストを行う際は、小規模なデータセットで実行し、動作確認を行った後に本番データに対して実行することをお勧めします。

## 6. エラーハンドリングとログ記録


本セクションでは、システムにおけるエラーハンドリング及びログ記録の方針について詳述します。ユーザーに対するフィードバックの提供方法、問題解決のための支援を目的としており、特にセンシティブ情報が含まれる場合のログ記録に関する注意点も取り上げます。

### エラーハンドリングの方針

システムは、特定のケースでのエラーまたは例外が発生する可能性があります。これを適切に処理するために、以下の方針が採用されています。

1. **例外処理メカニズムの実装**:
   - Pythonの例外処理を使用し、try-exceptブロックを導入することで、予期しないエラーに対する信頼性を高めます。
   - 不正なファイル形式や読み込みエラーに対しては、該当するエラーメッセージをキャッチし、ユーザーに明確なフィードバックを提供します。

2. **特定のエラーに対するフィードバック**:
   - 入力フォルダーが存在しない場合や、フォルダー内に処理可能なファイルが存在しない場合には、それぞれのエラーメッセージを用意し、ユーザーが次に取るべき行動を示します。

3. **警告の表示**:
   - 複数のファイルを処理する際、予期しないフォーマットのファイルが見つかった場合は警告をログに記録し、処理の継続を行います。

### ログ記録の導入

システムでは、操作の追跡やデバッグを目的としたログ記録機能を実装しています。具体的には、以下の要素が含まれます。

1. **ログの構成**:
   - Pythonの標準ライブラリである`logging`モジュールを使用して、異なるログレベル（INFO, WARNING, ERRORなど）でメッセージを出力します。
   - システムの主要な処理に関する情報、および発生したエラーや警告を記録します。

2. **ログのフォーマット**:
   - 各ログエントリは、タイムスタンプ、ログレベル、メッセージを含む形式で構成されます。これにより、ログの可読性が向上します。

3. **ログファイルのローテーション**:
   - 一定のサイズに達した場合、古いログファイルは自動的にアーカイブし、新しいログを記録するための新しいファイルを生成します。

### センシティブ情報のログ記録への注意点

システムでは、センシティブな情報が含まれる場合のログ記録には特に注意が必要です。以下のポイントに留意します。

1. **センシティブ情報の排除**:
   - ユーザーの個人情報や財務情報、認証情報などはログに記録しないように設計されています。

2. **マスク機能の実装**:
   - センシティブ情報を含む内容をログに書き出す必要がある場合、マスキング処理を施し、暗号化またはハイデン表示を行います。

3. **アクセス管理**:
   - ログファイルへのアクセスは制限され、適切な権限を持つユーザーのみが内容を確認できるようにします。

これにより、エラーハンドリングとログ記録に関する全体的なポリシーと実施内容が確立され、ユーザーの安全とシステムの信頼性を同時に向上させることが可能となります。

## 7. テスト計画


### テスト戦略

本プロジェクトのテスト計画は、ユニットテストと統合テストに重点を置き、コードの信頼性を確保するための包括的なアプローチを採用します。以下では、ユニットテストと統合テストの具体的な方法論を説明し、使用するテストツールの選定理由と目的を明示します。

### ユニットテスト

ユニットテストは、各モジュールや関数の動作を個別に検証する目的で実施します。これにより、コードリファクタリングや新機能追加時に発生する不具合を早期に発見することが可能となります。ユニットテストには以下の要素が含まれます：

- **テスト対象**:
  - `natural_sort_key(s)`関数: 文字列ソートの機能が正しく働くかをテストします。
  - 各カスタムモジュール（例: `function_fin`, `function_7_document_intelligence`）内の主要な関数も対象とします。

- **使用するツール**:
  - **unittest**: Python標準のテストフレームワークを使用し、簡潔で効率的なテストスクリプトを作成します。

- **テストケースの設計**:
  - 正常系、異常系のケースをそれぞれ作成し、期待される出力と実際の出力を比較します。
  - 特にエッジケース（例: 入力が空、未定義の文字列など）についても考慮します。

### 統合テスト

統合テストは、モジュール間の相互作用を検証し、全体としてのシステムの動作を確認するために実施します。以下がその詳細です：

- **テスト対象**:
  - スクリプト全体のフロー、特にAzure Document Intelligenceを通じてデータを抽出しExcelへの出力を行う過程を確認します。
  
- **使用するツール**:
  - **pytest**: より柔軟で強力なテスト機能を提供するため、unittestに加えてpytestを使用します。複雑なテストシナリオを簡潔に記述できるため、総合的なテストが容易になります。

- **テストケースの設計**:
  - 各ファイルパス設定とその出力結果の確認（例: `output_png_ocr.xlsx`、`output_UVDoc_ocr.xlsx`からのデータ統合など）。
  - エラーハンドリングの動作確認や、予期しない入力があった場合の挙動もテストします。

### センシティブ情報の取り扱い

テストプロセスにおいてセンシティブな情報（ファイルパス、不明なデータなど）が扱われる場合、以下の注意事項を遵守します：

- **マスキング**: センシティブな情報はテストログやエラーメッセージに直接出力しないようにします。必要に応じてマスキング処理を施し、情報が特定されないようにすることが求められます。
  
- **セキュアなテスト環境**: テストに利用するデータは特別に用意された環境で行い、開発環境や本番環境への影響を避けます。

- **レビューと承認**: センシティブ情報を扱うテストケースについては、必ずレビューを行い、適切な承認プロセスを経た上で実施します。

以上のテスト計画に従い、プロジェクトのコード品質を保証し、信頼性の高いシステムを構築します。

## 8. 将来的な拡張


本セクションでは、現在のスクリプトが持つ機能を基に、将来的な機能追加や改良について考察します。特に、ユーザーニーズやビジネス上の利点に関連し、プロジェクトの価値を高める提案を行います。

### 1. 自動化の強化

現在のスクリプトは請求書の処理を自動化していますが、今後はさらなる自動化を進めることで、ユーザーの作業負荷を軽減することが可能です。具体的には、以下の機能追加が考えられます。

- **定期的なスケジューリング**: スクリプトを定期的に実行する機能を追加することで、特定のフォルダ内の請求書を自動で処理し、定期的に更新されたファイルをユーザーに提供できるようになります。これにより、ユーザーは手作業での実行を省略でき、常に最新のデータにアクセス可能となります。

- **多様なデータソースの統合**: 現在のスクリプトは特定のフォルダ内のファイルを処理していますが、異なるシステムやフォーマット（例えば、PDFやCSV）からデータを直接取り込む機能を追加することで、データの入力源を多様化し、ユーザーにとっての利便性が向上します。

### 2. データ分析機能の充実

スクリプトが提供する請求書分析機能は、将来的にはより多角的なデータ分析機能を統合することが可能です。

- **データ可視化**: 得られた分析結果を元に、グラフやチャートを自動生成する機能を追加することで、ユーザーがデータの傾向を視覚的に把握できるようにします。これにより、経営状態の把握や意思決定をサポートします。

- **トレンド分析**: 過去の請求書データを蓄積し、売上や支出のトレンドを分析する機能を追加することで、ビジネスの動向を把握しやすくなります。これにより、顧客行動や市場の変化に迅速に対応できるようになります。

### 3. フィードバック機能の実装

ユーザーからのフィードバックを積極的に取り入れるために、スクリプト内にレポート機能を追加することを提案します。この機能により、ユーザーは処理結果に関するコメントや改善点を報告できるようになり、継続的な改善へとつなげることができます。

- **エラー報告機能**: スクリプトがエラーを検知した際に、自動的にログを生成し、ユーザーに通知する機能を追加します。この情報は、今後の改善に役立てるための貴重なデータとなります。

### 4. ビジネスプロセスの効率化

さらなる機能拡張として、ビジネスプロセス全般の効率化を図るために、他の業務ツールとの連携を強化することが考えられます。

- **API連携**: 他のビジネスツール（CRM、ERPなど）とのAPI連携を通じて、請求書データを他のシステムとリアルタイムで同期することが可能になります。これにより、データの二重入力を削減し、業務プロセス全体の効率を向上させます。

- **インタフェースの改善**: ユーザーインターフェースを構築し、操作を簡素化することにより、非技術者でも直感的にスクリプトを利用できるようにすることが期待されます。これにより、導入や使用における障壁を取り除くことができるでしょう。

### まとめ

将来的な拡張により、現在のスクリプトはユーザーのニーズに応え、更にはビジネス上の価値を高めるツールへ進化することが可能です。自動化、データ分析機能の強化、ユーザーからのフィードバックを反映した改善、他の業務ツールとの連携によって、システムはより価値の高いものとなり、プロジェクトの成長を促進するでしょう。

## 9. まとめ


本仕様書では、AzureのDocument Intelligenceを活用し、請求書ファイルからデータを抽出し、処理するPythonスクリプトの構成とその機能について詳述しました。プロジェクトの目的は、複数のソースから情報を統合し、最終的にExcelファイルとして出力することにあります。このプロセスにより、請求書の分析作業を効率化し、自動化することが可能になります。

プロジェクトの意義は、文書からの情報抽出やデータ統合の手間を削減し、ヒューマンエラーを最小限に抑える点にあります。ビジネスにおいて迅速かつ正確なデータ処理が求められる中、こうした自動化されたソリューションがもたらす効果は大きいと考えられます。

今後の方向性としては、さらなる機能の追加や、処理速度の向上、エラー処理機能の強化が挙げられます。また、ユーザーインターフェースの改善や、複数の形式の文書に対応できる柔軟性の追加なども検討されるべきです。

重要なポイントとしては、プロジェクトに含まれる各モジュールが相互に連携し、全体として一貫した処理フローを形成している点です。また、各関数の役割が明確であり、保守性の高いコード設計が実現されていることも強調されます。これにより、プロジェクトの拡張や改善が円滑に行える基盤が整っています。

今後の展望と合わせて、本プロジェクトがもたらす便益を最大限に活用できるよう、継続的な改善と最適化を進めていく方針です。

